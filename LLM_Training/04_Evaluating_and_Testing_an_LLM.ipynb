{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating and Testing a Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we import the necessary libraries for evaluating and testing a language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "from random import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "from random import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we load the train and test data that we will be using to evaluate and test the language model and preprocess it by tokenizing and removing stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into a Pandas dataframe\n",
    "train_data_path = './datasets/train.csv'\n",
    "test_data_path = './datasets/test.csv'\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# Preprocess data\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "train_data['tokens'] = train_data['text'].apply(preprocess_text)\n",
    "test_data['tokens'] = test_data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Custom Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we define a custom dataset and data loader for the language model, using a sliding window approach to generate sequences of a fixed length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelDataset(Dataset):\n",
    "    def __init__(self, data, seq_len):\n",
    "        self.data = [word for tokens in data for word in tokens]\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx+self.seq_len]\n",
    "        y = self.data[idx+self.seq_len]\n",
    "        return x, y\n",
    "\n",
    "train_dataset = LanguageModelDataset(train_data['tokens'], 50)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define a Function to Evaluate Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we define a function to evaluate language models using a given dataset and criterion. This function computes the loss and perplexity of the model on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    n_tokens = 0\n",
    "    with torch.no_grad():\n",
    "        for tokens, targets in data:\n",
    "            tokens = torch.LongTensor(tokens).to(device)\n",
    "            targets = torch.LongTensor(targets).to(device)\n",
    "\n",
    "            h = (torch.zeros(model.lstm.num_layers, tokens.shape[0], model.lstm.hidden_size).to(device),\n",
    "                 torch.zeros(model.lstm.num_layers, tokens.shape[0], model.lstm.hidden_size).to(device))\n",
    "\n",
    "            output, h = model(tokens, h)\n",
    "            loss = criterion(output, targets.view(-1))\n",
    "            total_loss += loss.item() * len(tokens)\n",
    "            n_tokens += len(tokens)\n",
    "    avg_loss = total_loss / n_tokens\n",
    "    perplexity = np.exp(avg_loss)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Function to Test Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we define a function to test language models using a given dataset. This function computes the accuracy of the model on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for tokens, target in data:\n",
    "            tokens = torch.LongTensor(tokens).to(device)\n",
    "            target = torch.LongTensor(target).to(device)\n",
    "\n",
    "            h = (torch.zeros(model.lstm.num_layers, tokens.shape[0], model.lstm.hidden_size).to(device),\n",
    "                 torch.zeros(model.lstm.num_layers, tokens.shape[0], model.lstm.hidden_size).to(device))\n",
    "\n",
    "            output, h = model(tokens, h)\n",
    "            predictions = torch.argmax(output, dim=1)\n",
    "            correct += (predictions == target).sum().item()\n",
    "            total += len(target)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers=1):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        x = self.embedding(x)\n",
    "        x, h = self.lstm(x, h)\n",
    "        x = x.contiguous().view(-1, x.shape[2])\n",
    "        x = self.fc(x)\n",
    "        return x, h\n",
    "    \n",
    "vocab_size = 257\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "sequence_length = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'model.pt'\n",
    "model = LanguageModel(vocab_size, embedding_dim, hidden_dim, num_layers).to(device)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out LLM's Inferencing using Hugging Face LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/en/llm_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethos",
   "language": "python",
   "name": "ethos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
